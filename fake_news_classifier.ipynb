{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "fake_news_classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJUn20NViG1h",
        "colab_type": "text"
      },
      "source": [
        "# 1) Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0eKbpUU_Xl",
        "colab_type": "text"
      },
      "source": [
        "As usual we start loading the packages that we will use in our notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6sn75StU_Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikO9fTgUU_Xv",
        "colab_type": "code",
        "outputId": "bd67d895-f38d-4326-bac8-a335a6ca7429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#PRINT VERSION!!\n",
        "tf.__version__"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7TjD_WiTTR",
        "colab_type": "text"
      },
      "source": [
        "## 2) Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA7mgGA3WOvD",
        "colab_type": "code",
        "outputId": "0effeae7-c91d-4783-ac6d-5145371249bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget -O train.csv https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/blob/master/section_4_notebooks/train.csv?raw=true"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-01 10:57:14--  https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/blob/master/section_4_notebooks/train.csv?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/raw/master/section_4_notebooks/train.csv [following]\n",
            "--2020-06-01 10:57:15--  https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/raw/master/section_4_notebooks/train.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/master/section_4_notebooks/train.csv [following]\n",
            "--2020-06-01 10:57:15--  https://media.githubusercontent.com/media/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/master/section_4_notebooks/train.csv\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98628550 (94M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  94.06M   229MB/s    in 0.4s    \n",
            "\n",
            "2020-06-01 10:57:16 (229 MB/s) - ‘train.csv’ saved [98628550/98628550]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcXPfWmiXeh",
        "colab_type": "text"
      },
      "source": [
        "## 3) Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrCRN2VmU_X5",
        "colab_type": "code",
        "outputId": "a09ff3ae-8ef8-483a-9278-21d920f568c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")#here we have the dataset we extracted\n",
        "print(\"Dataset length: \", len(train_df))\n",
        "train_df.head(n=10)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20795</th>\n",
              "      <td>20795</td>\n",
              "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
              "      <td>Jerome Hudson</td>\n",
              "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20796</th>\n",
              "      <td>20796</td>\n",
              "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
              "      <td>Benjamin Hoffman</td>\n",
              "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20797</th>\n",
              "      <td>20797</td>\n",
              "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
              "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
              "      <td>The Macy’s of today grew from the union of sev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20798</th>\n",
              "      <td>20798</td>\n",
              "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
              "      <td>Alex Ansary</td>\n",
              "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20799</th>\n",
              "      <td>20799</td>\n",
              "      <td>What Keeps the F-35 Alive</td>\n",
              "      <td>David Swanson</td>\n",
              "      <td>David Swanson is an author, activist, journa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20800 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... label\n",
              "0          0  ...     1\n",
              "1          1  ...     0\n",
              "2          2  ...     1\n",
              "3          3  ...     1\n",
              "4          4  ...     1\n",
              "...      ...  ...   ...\n",
              "20795  20795  ...     0\n",
              "20796  20796  ...     0\n",
              "20797  20797  ...     0\n",
              "20798  20798  ...     1\n",
              "20799  20799  ...     1\n",
              "\n",
              "[20800 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR6CU5chkBl4",
        "colab_type": "text"
      },
      "source": [
        "# 4) Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegdnBYCU_Yn",
        "colab_type": "code",
        "outputId": "d336e0b8-81d6-429d-8dc8-33c3037cf9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df['author'].unique()) #we print the length, not a big one but sufficient"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVp4p1-BU_Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['title_lower'] = train_df[\"title\"].str.lower()\n",
        "train_df['title_no_punctuation'] = train_df['title_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['title_no_punctuation'] = train_df[\"title_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_yfhhbU_Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text_lower'] = train_df[\"text\"].str.lower()\n",
        "train_df['text_no_punctuation'] = train_df['text_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['text_no_punctuation'] = train_df[\"text_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUsptq6hU_Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['author_lower'] = train_df[\"author\"].str.lower()\n",
        "train_df['author_no_spaces'] = train_df['author_lower'].str.replace(' ','_')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1dHWuPZU_Y8",
        "colab_type": "code",
        "outputId": "5c848794-1034-41d8-f60f-9977b59ce315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_df['author_no_spaces'].head() #in this way we can treat each author as a word."
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         darrell_lucus\n",
              "1       daniel_j._flynn\n",
              "2    consortiumnews.com\n",
              "3       jessica_purkiss\n",
              "4        howard_portnoy\n",
              "Name: author_no_spaces, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS5Ddw6PU_Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features=5000 #we set maximum number of words to 5000\n",
        "maxlen=400 #we set maximum sequence length to 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPR06axsU_ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features) #again tokenizer step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZeSinjU_ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok.fit_on_texts(list(train_df['text_no_punctuation'])+list(train_df['title_no_punctuation'])+list(train_df['author_no_spaces'].astype(str))) #fit to cleaned text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7dUTwOU_ZH",
        "colab_type": "code",
        "outputId": "39591e26-bea5-41f2-f529-6ef9a0191292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tok.word_index))\n",
        "vocab_size = len(tok.word_index) + 1 \n",
        "#this represents the number of words that we tokenize different from max_features but necessary for\n",
        "#the definition of the dimension of the embedding space"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "216068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUSPM4kOsLIe",
        "colab_type": "text"
      },
      "source": [
        "# 5) Prepeare Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhSzTLi6U_ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df = tok.texts_to_sequences(list(train_df['text_no_punctuation'])) #this is how we create sequences\n",
        "text_df = tf.keras.preprocessing.sequence.pad_sequences(text_df, maxlen=maxlen) #let's execute pad step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCIllpP3U_ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_df = tok.texts_to_sequences(list(train_df['title_no_punctuation'])) #this is how we create sequences\n",
        "title_df = tf.keras.preprocessing.sequence.pad_sequences(title_df, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBv3Lk6MU_ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "author_df = tok.texts_to_sequences(list(train_df['author_no_spaces'].astype(str))) #this is how we create sequences\n",
        "author_df = tf.keras.preprocessing.sequence.pad_sequences(author_df, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyocIPRgU_ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = author_df #title_df + text_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-mezVpU_ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split #divide into train and test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDnbUuiKU_Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3HWq7IPU_Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50 #this is the final dimension of the embedding space.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A5aeKsCq35r",
        "colab_type": "text"
      },
      "source": [
        "# 6) Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPtb9W4SU_Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(input_dim=vocab_size, #embedding input\n",
        "                           output_dim=embedding_dim,#embedding output\n",
        "                           input_length=maxlen), #maximum length of an input sequence\n",
        "  tf.keras.layers.Flatten(), #flatten layer\n",
        "\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) #no more softmax\n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-XCq-tU_Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',#no more categorical_crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3U7WmP7U_Zl",
        "colab_type": "code",
        "outputId": "ff58c293-95e7-4dc2-8fd4-920308401599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary() #here we show the architecture "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 400, 50)           10803450  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 20001     \n",
            "=================================================================\n",
            "Total params: 10,823,451\n",
            "Trainable params: 10,823,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0Xuw1WsrU_Zn",
        "colab_type": "code",
        "outputId": "a0081aae-532c-40ab-918c-138bc53e5781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train), epochs=1) #let's fit the model"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "585/585 [==============================] - 65s 112ms/step - loss: 0.4647 - accuracy: 0.7682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9ad9731588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfV5bPzeq9ti",
        "colab_type": "text"
      },
      "source": [
        "# 7) Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGeScY-GU_Zq",
        "colab_type": "code",
        "outputId": "96db2170-8f74-4049-b056-2aa7651669e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#results text, title and author [0.1477214220767984, 0.9447115384615384]\n",
        "#results text, title [0.13193302869510193, 0.9461538461538461]\n",
        "#results author [0.3442320129046073, 0.8211538461538461]\n",
        "model.evaluate(np.array(X_test), np.array(y_test)) "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3689170181751251, 0.8149038553237915]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    }
  ]
}