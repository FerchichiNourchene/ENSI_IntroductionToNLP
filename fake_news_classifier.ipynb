{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "fake_news_classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJUn20NViG1h",
        "colab_type": "text"
      },
      "source": [
        "# 1) Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0eKbpUU_Xl",
        "colab_type": "text"
      },
      "source": [
        "As usual we start loading the packages that we will use in our notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6sn75StU_Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikO9fTgUU_Xv",
        "colab_type": "code",
        "outputId": "590c688f-b8b7-4c09-dc97-c361bc2b1495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#PRINT VERSION!!\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7TjD_WiTTR",
        "colab_type": "text"
      },
      "source": [
        "## 2) Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA7mgGA3WOvD",
        "colab_type": "code",
        "outputId": "57f51c58-1ea3-4d1d-ad30-da0dbe9c4199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget -O train.csv https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/blob/master/section_4_notebooks/train.csv?raw=true"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-01 11:53:42--  https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/blob/master/section_4_notebooks/train.csv?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/raw/master/section_4_notebooks/train.csv [following]\n",
            "--2020-06-01 11:53:42--  https://github.com/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/raw/master/section_4_notebooks/train.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/master/section_4_notebooks/train.csv [following]\n",
            "--2020-06-01 11:53:43--  https://media.githubusercontent.com/media/PacktPublishing/Advanced-NLP-Projects-with-TensorFlow-2.0/master/section_4_notebooks/train.csv\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98628550 (94M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "\rtrain.csv             0%[                    ]       0  --.-KB/s               \rtrain.csv            14%[=>                  ]  13.33M  66.6MB/s               \rtrain.csv            72%[=============>      ]  68.39M   171MB/s               \rtrain.csv           100%[===================>]  94.06M   201MB/s    in 0.5s    \n",
            "\n",
            "2020-06-01 11:53:43 (201 MB/s) - ‘train.csv’ saved [98628550/98628550]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcXPfWmiXeh",
        "colab_type": "text"
      },
      "source": [
        "## 3) Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrCRN2VmU_X5",
        "colab_type": "code",
        "outputId": "e59deace-f384-46ac-9560-c6bd9f141394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")#here we have the dataset we extracted\n",
        "print(\"Dataset length: \", len(train_df))\n",
        "train_df.head(n=10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length:  20800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
              "      <td>Alissa J. Rubin</td>\n",
              "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
              "      <td>Megan Twohey and Scott Shane</td>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "5   5  ...     0\n",
              "6   6  ...     1\n",
              "7   7  ...     0\n",
              "8   8  ...     0\n",
              "9   9  ...     0\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUXpc47IuVeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = train_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR6CU5chkBl4",
        "colab_type": "text"
      },
      "source": [
        "# 4) Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegdnBYCU_Yn",
        "colab_type": "code",
        "outputId": "1ce3177a-90cc-4a41-e5f8-d60ebb45a08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df['author'].unique()) #we print the length, not a big one but sufficient"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVp4p1-BU_Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['title_lower'] = train_df[\"title\"].str.lower()\n",
        "train_df['title_no_punctuation'] = train_df['title_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['title_no_punctuation'] = train_df[\"title_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_yfhhbU_Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text_lower'] = train_df[\"text\"].str.lower()\n",
        "train_df['text_no_punctuation'] = train_df['text_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['text_no_punctuation'] = train_df[\"text_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUsptq6hU_Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['author_lower'] = train_df[\"author\"].str.lower()\n",
        "train_df['author_no_spaces'] = train_df['author_lower'].str.replace(' ','_')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1dHWuPZU_Y8",
        "colab_type": "code",
        "outputId": "1760294d-ad5f-42d1-9f4f-9115017f1f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train_df['author_no_spaces'].head() #in this way we can treat each author as a word."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         darrell_lucus\n",
              "1       daniel_j._flynn\n",
              "2    consortiumnews.com\n",
              "3       jessica_purkiss\n",
              "4        howard_portnoy\n",
              "Name: author_no_spaces, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS5Ddw6PU_Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features=5000 #we set maximum number of words to 5000\n",
        "maxlen=400 #we set maximum sequence length to 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPR06axsU_ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features) #again tokenizer step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZeSinjU_ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok.fit_on_texts(list(train_df['text_no_punctuation'])+list(train_df['title_no_punctuation'])+list(train_df['author_no_spaces'].astype(str))) #fit to cleaned text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7dUTwOU_ZH",
        "colab_type": "code",
        "outputId": "410e90a7-135d-41cb-d460-01cd974e8bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tok.word_index))\n",
        "vocab_size = len(tok.word_index) + 1 \n",
        "#this represents the number of words that we tokenize different from max_features but necessary for\n",
        "#the definition of the dimension of the embedding space"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "216068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUSPM4kOsLIe",
        "colab_type": "text"
      },
      "source": [
        "# 5) Prepeare Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhSzTLi6U_ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df = tok.texts_to_sequences(list(train_df['text_no_punctuation'])) #this is how we create sequences\n",
        "text_df = tf.keras.preprocessing.sequence.pad_sequences(text_df, maxlen=maxlen) #let's execute pad step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCIllpP3U_ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_df = tok.texts_to_sequences(list(train_df['title_no_punctuation'])) #this is how we create sequences\n",
        "title_df = tf.keras.preprocessing.sequence.pad_sequences(title_df, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBv3Lk6MU_ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "author_df = tok.texts_to_sequences(list(train_df['author_no_spaces'].astype(str))) #this is how we create sequences\n",
        "author_df = tf.keras.preprocessing.sequence.pad_sequences(author_df, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyocIPRgU_ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = author_df #title_df + text_df  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-mezVpU_ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split #divide into train and test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDnbUuiKU_Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3HWq7IPU_Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50 #this is the final dimension of the embedding space.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A5aeKsCq35r",
        "colab_type": "text"
      },
      "source": [
        "# 6) Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPtb9W4SU_Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(input_dim=vocab_size, #embedding input\n",
        "                           output_dim=embedding_dim,#embedding output\n",
        "                           input_length=maxlen), #maximum length of an input sequence\n",
        "  tf.keras.layers.Flatten(), #flatten layer\n",
        "\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) #no more softmax\n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-XCq-tU_Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',#no more categorical_crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3U7WmP7U_Zl",
        "colab_type": "code",
        "outputId": "fcae367d-194c-40e7-83a8-47f0f2547c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary() #here we show the architecture "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 50)           10803450  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 20001     \n",
            "=================================================================\n",
            "Total params: 10,823,451\n",
            "Trainable params: 10,823,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0Xuw1WsrU_Zn",
        "colab_type": "code",
        "outputId": "6b455ce5-310b-4a22-acdd-07b85387aabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train), epochs=1) #let's fit the model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "585/585 [==============================] - 70s 120ms/step - loss: 0.4631 - accuracy: 0.7729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2f69e8a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfV5bPzeq9ti",
        "colab_type": "text"
      },
      "source": [
        "# 7) Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGeScY-GU_Zq",
        "colab_type": "code",
        "outputId": "5497ff4b-043d-4979-f3b2-4187767c9a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#results text, title and author [0.1477214220767984, 0.9447115384615384]\n",
        "#results text, title [0.13193302869510193, 0.9461538461538461]\n",
        "#results author [0.3442320129046073, 0.8211538461538461]\n",
        "model.evaluate(np.array(X_test), np.array(y_test)) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3674405813217163, 0.8125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}